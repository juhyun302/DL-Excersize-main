{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720081926684
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\EL19\\Downloads\\DL-Excersize-main\\DL-Excersize-main\\notebooks\\DL3_20241006\\ch04\n",
            "c:\\Users\\EL19\\Downloads\\DL-Excersize-main\\DL-Excersize-main\\notebooks\\DL3_20241006\n",
            "0.13898333333333332 0.1381\n",
            "0.9035833333333333 0.9072\n",
            "0.9239833333333334 0.9224\n",
            "0.93635 0.9378\n",
            "0.9447166666666666 0.9441\n",
            "0.9512833333333334 0.9501\n",
            "0.9569 0.955\n",
            "0.9601333333333333 0.958\n",
            "0.9649666666666666 0.962\n",
            "0.9676333333333333 0.9635\n",
            "0.96925 0.9649\n",
            "0.9716 0.9679\n",
            "0.9733166666666667 0.968\n",
            "0.97395 0.9695\n",
            "0.9747 0.9684\n",
            "0.9772166666666666 0.9708\n",
            "0.9790666666666666 0.9724\n"
          ]
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "import os, sys\n",
        "print(os.getcwd())\n",
        "current_dir = os.path.dirname(os.getcwd())\n",
        "print(current_dir)\n",
        "os.chdir(current_dir)\n",
        "\n",
        "#sys.path.append(parent_dir)\n",
        "\n",
        "#import torch\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from ch04.two_layer_net import TwoLayerNet\n",
        "\n",
        "# 데이터 읽기\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np. random. choice(train_size, batch_size)\n",
        "    x_batch = x_train [batch_mask]\n",
        "    t_batch = t_train [batch_mask]\n",
        "\n",
        "    # 기울기 계산\n",
        "    #grad = network. numerical_gradient(x_batch, t_batch) #\n",
        "    grad= network.gradient(x_batch, t_batch) # 오차역전파법\n",
        "\n",
        "    # 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network. params [key] -= learning_rate * grad [key]\n",
        "\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
